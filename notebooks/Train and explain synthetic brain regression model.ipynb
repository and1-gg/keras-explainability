{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e29111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "IMAGE_SIZE = 32\n",
    "NUM_TUNNELS = 6\n",
    "MAX_RADIUS = 10\n",
    "N = 1000\n",
    "\n",
    "def key(x: Any):\n",
    "    if isinstance(x, tuple):\n",
    "        return f'{int(x[0][0])}-{int(x[1][0])}-{int(x[2][0])}'\n",
    "    else:\n",
    "        return f'{int(x[0])}-{int(x[1])}-{int(x[2])}'\n",
    "\n",
    "def drill(brain: np.ndarray, surface: np.ndarray, center: np.ndarray, width: float, \n",
    "          inside_keys: set, idx: np.ndarray) -> np.ndarray:\n",
    "    current_idx = np.random.choice(np.arange(len(surface)))\n",
    "    current = surface[current_idx]\n",
    "    direction = center - current\n",
    "    direction = direction / np.sum(np.abs(direction))\n",
    "    current_idx = tuple(np.expand_dims(current+direction, -1).astype(int))\n",
    "    \n",
    "    while key(current_idx) in inside_keys:\n",
    "        vertex_radius = np.random.uniform(width // 2, 1)\n",
    "        vertex_distances = euclidean_distances(idx, np.asarray(current_idx).reshape(1, 3))[:,0]\n",
    "        pocket = vertex_distances <= vertex_radius\n",
    "        brain[tuple(idx[pocket].T)] = 0\n",
    "\n",
    "        next = current + direction\n",
    "        direction = next - current\n",
    "        direction[0] = np.random.normal(direction[0], np.abs(direction[0] / 3))\n",
    "        direction[1] = np.random.normal(direction[0], np.abs(direction[1] / 3))\n",
    "        direction[2] = np.random.normal(direction[0], np.abs(direction[2] / 3))\n",
    "        direction = direction / np.sum(np.abs(direction))\n",
    "        current = next\n",
    "        current_idx = tuple(np.expand_dims(current, -1).astype(int))\n",
    "        \n",
    "    return brain\n",
    "\n",
    "def create_brain(size: int, width: int, num_tunnels: int = 1):\n",
    "    brain = np.zeros((size, size, size, 1))\n",
    "    \n",
    "    center = np.random.randint(7 * size//16, 9*size//16, 3)\n",
    "    radius = np.random.randint(size//2-6, size//2-2)\n",
    "    \n",
    "    idx = np.asarray(np.meshgrid(*[np.arange(size) for _ in range(3)])).T.reshape(-1, 3)\n",
    "    distances = euclidean_distances(idx, center.reshape(1, -1))[:,0]\n",
    "    inside = distances <= radius\n",
    "    surface = np.isclose(distances, radius, atol=1e-1)\n",
    "    surface = idx[surface]\n",
    "    \n",
    "    brain[tuple(idx[inside].T)] = np.random.uniform(0.25, 1, (len(idx[inside]), 1))\n",
    "    brain[tuple(idx[surface].T)] = np.random.uniform(0.25, 1, (len(idx[surface]), 1))\n",
    "    \n",
    "    inside_keys = set([key(x) for x in idx[inside]]) | set([key(x) for x in surface])\n",
    "    \n",
    "    for _ in range(num_tunnels):\n",
    "        drill(brain, surface, center, width, inside_keys, idx)\n",
    "    \n",
    "    return brain\n",
    "\n",
    "X = []\n",
    "y = np.random.randint(1, MAX_RADIUS + 1, N)\n",
    "\n",
    "for i in range(len(y)):\n",
    "    X.append(create_brain(IMAGE_SIZE, width=y[i], num_tunnels=NUM_TUNNELS))\n",
    "    print(f'{i+1}/{N}')\n",
    "\n",
    "    \n",
    "fig, ax = plt.subplots(10, 8, figsize=(15, 15))\n",
    "\n",
    "for i in range(1, MAX_RADIUS + 1):\n",
    "    idx = np.where(y == i)[0][0]\n",
    "    \n",
    "    for j in range(8):\n",
    "        ax[i-1][j].imshow(X[idx][12+j], cmap='Greys_r')\n",
    "        ax[i-1][j].axis('off')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab18e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.figure_factory import create_distplot\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y).reshape((-1, 1))\n",
    "train_X = X[:int(0.6*len(X))]\n",
    "train_y = y[:int(0.6*len(X))]\n",
    "\n",
    "val_X = X[int(0.6*len(X)):int(0.8*len(X))]\n",
    "val_y = y[int(0.6*len(X)):int(0.8*len(X))]\n",
    "\n",
    "test_X = X[int(0.8*len(X)):]\n",
    "test_y = y[int(0.8*len(X)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ab5979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Activation, BatchNormalization, Conv3D, Dense, Dropout, Input, \\\n",
    "                                    GlobalAveragePooling3D, MaxPooling3D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "regularizer = l2(1e-3)\n",
    "depths = [32, 64, 128, 256, 256, 64]\n",
    "activation='relu'\n",
    "dropout=0.5\n",
    "\n",
    "inputs = Input((IMAGE_SIZE, IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "x = inputs\n",
    "\n",
    "for i in range(3):\n",
    "    x = Conv3D(depths[i], (3, 3, 3), padding='SAME',\n",
    "               activation=None, kernel_regularizer=regularizer,\n",
    "               bias_regularizer=regularizer)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = MaxPooling3D((2, 2, 2))(x)\n",
    "\n",
    "x = Conv3D(depths[-1], (1, 1, 1), padding='SAME', activation=None,\n",
    "           kernel_regularizer=regularizer)(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Activation(activation)(x)\n",
    "x = GlobalAveragePooling3D()(x)\n",
    "\n",
    "x = Dense(32, activation=None)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dropout(dropout)(x)\n",
    "x = Dense(1, activation=None)(x)\n",
    "\n",
    "model = Model(inputs, x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846b773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(1e-3), metrics=['mae'])\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(\n",
    "        monitor=\"loss\",\n",
    "        factor=0.1,\n",
    "        patience=10,\n",
    "        min_lr=1e-5\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0,\n",
    "        patience=50,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(train_X, train_y, \n",
    "                    validation_data=(val_X, val_y), \n",
    "                    batch_size=32,\n",
    "                    epochs=500,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "\n",
    "traces = [\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(history.history['loss'])),\n",
    "        y=history.history['loss'],\n",
    "        name='Training loss'\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(history.history['loss'])),\n",
    "        y=history.history['val_loss'],\n",
    "        name='Validation loss'\n",
    "    )\n",
    "]\n",
    "\n",
    "iplot(go.Figure(traces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc58aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "train_predictions = model.predict(train_X)\n",
    "val_predictions = model.predict(val_X)\n",
    "test_predictions = model.predict(test_X)\n",
    "\n",
    "fig = make_subplots(1, 3)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=train_y.squeeze(),\n",
    "        y=train_predictions.squeeze(),\n",
    "        mode='markers',\n",
    "        showlegend=False\n",
    "    )\n",
    ", row=1, col=1)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 11],\n",
    "        y=[0, 11],\n",
    "        mode='lines',\n",
    "        showlegend=False\n",
    "    )\n",
    ", row=1, col=1)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=val_y.squeeze(),\n",
    "        y=val_predictions.squeeze(),\n",
    "        mode='markers',\n",
    "        showlegend=False\n",
    "    )\n",
    ", row=1, col=2)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 11],\n",
    "        y=[0, 11],\n",
    "        mode='lines',\n",
    "        showlegend=False\n",
    "    )\n",
    ", row=1, col=2)\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=test_y.squeeze(),\n",
    "        y=test_predictions.squeeze(),\n",
    "        mode='markers',\n",
    "        showlegend=False\n",
    "    )\n",
    ", row=1, col=3)\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[0, 11],\n",
    "        y=[0, 11],\n",
    "        mode='lines',\n",
    "        showlegend=False\n",
    "    )\n",
    ", row=1, col=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896fe0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainability import LayerwiseRelevancePropagator, LRPStrategy\n",
    "\n",
    "\n",
    "strategy = LRPStrategy(\n",
    "    layers=[\n",
    "        {'flat': True},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'epsilon': 0.25},\n",
    "    ]\n",
    ")\n",
    "\n",
    "explainer = LayerwiseRelevancePropagator(model, layer=-1, idx=0, strategy=strategy)\n",
    "\n",
    "for i in range(1, MAX_RADIUS + 1):\n",
    "    fig, ax = plt.subplots(2, 8, figsize=(15, 3))\n",
    "    idx = np.where(test_y == i)[0][0]\n",
    "    explanations = explainer(test_X[idx:(idx + 1)])\n",
    "    explanations = explanations / np.amax(np.abs(explanations))\n",
    "    \n",
    "    for j in range(8):\n",
    "        ax[0][j].imshow(test_X[idx,12+j], cmap='Greys_r')\n",
    "        ax[0][j].axis('off')\n",
    "        ax[1][j].imshow(explanations[0,12+j], cmap='seismic', clim=(-1, 1))\n",
    "        ax[1][j].axis('off')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd6f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.colors import DEFAULT_PLOTLY_COLORS\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "brain = np.zeros((IMAGE_SIZE, IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "\n",
    "center = np.asarray([IMAGE_SIZE // 2 for _ in range(3)])\n",
    "radius = IMAGE_SIZE // 2-2\n",
    "\n",
    "idx = np.asarray(np.meshgrid(*[np.arange(IMAGE_SIZE) for _ in range(3)])).T.reshape(-1, 3)\n",
    "distances = euclidean_distances(idx, center.reshape(1, -1))[:,0]\n",
    "inside = distances <= radius\n",
    "surface = np.isclose(distances, radius, atol=1e-1)\n",
    "surface = idx[surface]\n",
    "\n",
    "brain[tuple(idx[inside].T)] = np.random.uniform(0.25, 1, (len(idx[inside]), 1))\n",
    "brain[tuple(idx[surface].T)] = np.random.uniform(0.25, 1, (len(idx[surface]), 1))\n",
    "\n",
    "inside_keys = set([key(x) for x in idx[inside]])\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for _ in range(1, 2 * NUM_TUNNELS + 1):\n",
    "    brain = drill(brain, surface, center, 5, inside_keys, idx)\n",
    "    predictions.append(model.predict(np.expand_dims(brain, 0))[0,0])\n",
    "    \n",
    "fig, ax = plt.subplots(1, 8, figsize=(15, 2))\n",
    "\n",
    "for i in range(8):\n",
    "    ax[i].imshow(brain[12+i], cmap='Greys_r')\n",
    "    ax[i].axis('off')\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "traces = [\n",
    "    go.Scatter(\n",
    "        x=np.arange(1, 41),\n",
    "        y=predictions,\n",
    "        mode='markers+lines',\n",
    "        showlegend=False,\n",
    "        marker={\n",
    "            'color': DEFAULT_PLOTLY_COLORS[0]\n",
    "        },\n",
    "        line={\n",
    "            'color': DEFAULT_PLOTLY_COLORS[0]\n",
    "        }\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        x=[1, 2*NUM_TUNNELS],\n",
    "        y=[5, 5],\n",
    "        mode='lines',\n",
    "        showlegend=False,\n",
    "        line={\n",
    "            'color': DEFAULT_PLOTLY_COLORS[2],\n",
    "            'dash': 'dash'\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title={\n",
    "        'x': 0.5,\n",
    "        'text': 'Prediction as a function of number of tunnels'\n",
    "    },\n",
    "    xaxis={\n",
    "        'title': 'Number of tunnels'\n",
    "    },\n",
    "    yaxis={\n",
    "        'title': 'Prediction'\n",
    "    }\n",
    ")\n",
    "\n",
    "iplot(go.Figure(traces, layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca303ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "brain = np.zeros((IMAGE_SIZE, IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "\n",
    "center = np.asarray([IMAGE_SIZE // 2 for _ in range(3)])\n",
    "radius = IMAGE_SIZE // 2-2\n",
    "\n",
    "idx = np.asarray(np.meshgrid(*[np.arange(IMAGE_SIZE) for _ in range(3)])).T.reshape(-1, 3)\n",
    "distances = euclidean_distances(idx, center.reshape(1, -1))[:,0]\n",
    "inside = distances <= radius\n",
    "surface = np.isclose(distances, radius, atol=1e-1)\n",
    "surface = idx[surface]\n",
    "\n",
    "brain[tuple(idx[inside].T)] = np.random.uniform(0.25, 1, (len(idx[inside]), 1))\n",
    "brain[tuple(idx[surface].T)] = np.random.uniform(0.25, 1, (len(idx[surface]), 1))\n",
    "\n",
    "inside_keys = set([key(x) for x in idx[inside]])\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for i in range(1, NUM_TUNNELS + 1):\n",
    "    width = 2 + (6 * (i % 2))\n",
    "    brain = drill(brain, surface, center, width, inside_keys, idx)\n",
    "    predictions.append(model.predict(np.expand_dims(brain, 0))[0,0])\n",
    "    \n",
    "fig, ax = plt.subplots(1, 8, figsize=(15, 2))\n",
    "\n",
    "for i in range(8):\n",
    "    ax[i].imshow(brain[12+i], cmap='Greys_r')\n",
    "    ax[i].axis('off')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "colours = [DEFAULT_PLOTLY_COLORS[(i+1) % 2] for i in range(len(predictions))]\n",
    "    \n",
    "traces = [\n",
    "    go.Scatter(\n",
    "        x=np.arange(1, NUM_TUNNELS + 1),\n",
    "        y=predictions,\n",
    "        mode='markers+lines',\n",
    "        showlegend=False,\n",
    "        marker={\n",
    "            'color': colours\n",
    "        },\n",
    "        line={\n",
    "            'color': DEFAULT_PLOTLY_COLORS[0]\n",
    "        },\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        x=[1, NUM_TUNNELS],\n",
    "        y=[5, 5],\n",
    "        mode='lines',\n",
    "        showlegend=False,\n",
    "        line={\n",
    "            'color': DEFAULT_PLOTLY_COLORS[2],\n",
    "            'dash': 'dash'\n",
    "        }\n",
    "    )\n",
    "]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title={\n",
    "        'x': 0.5,\n",
    "        'text': 'Prediction as a function of number of tunnels'\n",
    "    },\n",
    "    xaxis={\n",
    "        'title': 'Number of tunnels'\n",
    "    },\n",
    "    yaxis={\n",
    "        'title': 'Prediction'\n",
    "    }\n",
    ")\n",
    "\n",
    "iplot(go.Figure(traces, layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8119b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = LayerwiseRelevancePropagator(model, layer=20, idx=0, strategy=strategy)\n",
    "explanations = explainer.predict(np.expand_dims(brain, 0))[0]\n",
    "explanations = explanations / np.amax(np.abs(explanations))\n",
    "\n",
    "fig, ax = plt.subplots(8, 8, figsize=(15, 8))\n",
    "\n",
    "for i in range(0, 8, 2):\n",
    "    for j in range(8):\n",
    "        idx = ((i // 2) * 8)+ j\n",
    "        \n",
    "        ax[i][j].imshow(brain[idx], cmap='Greys_r')\n",
    "        ax[i][j].axis('off')\n",
    "        ax[i+1][j].imshow(explanations[idx], cmap='seismic', clim=(-1, 1))\n",
    "        ax[i+1][j].axis('off')\n",
    "        \n",
    "plt.savefig('standard.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31eb345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(model.input, model.layers[17].output)\n",
    "encodings = encoder.predict(test_X)\n",
    "group_idx = np.where(test_y == 5)[0]\n",
    "group_encodings = encodings[group_idx]\n",
    "mean_encoding = np.mean(group_encodings, axis=0)\n",
    "encoding_stddev = np.std(group_encodings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139ddb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainability import RestructuredLRP\n",
    "    \n",
    "restructured_lrp = RestructuredLRP(model, layer=20, idx=0, bottleneck=17, strategy=strategy)\n",
    "restructured_explanations = restructured_lrp.predict([np.expand_dims(brain, 0), \n",
    "                                                      np.expand_dims(mean_encoding, 0)])[0]\n",
    "restructured_explanations = restructured_explanations / np.amax(np.abs(restructured_explanations))\n",
    "\n",
    "fig, ax = plt.subplots(4, 8, figsize=(15, 4))\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "    ax[0][i].imshow(brain[12+i], cmap='Greys_r')\n",
    "    ax[0][i].axis('off')\n",
    "    ax[1][i].imshow(explanations[12+i], cmap='seismic', clim=(-1, 1))\n",
    "    ax[1][i].axis('off')\n",
    "    ax[2][i].imshow(restructured_explanations[12+i], cmap='seismic', clim=(-1, 1))\n",
    "    ax[2][i].axis('off')\n",
    "    ax[3][i].imshow(restructured_explanations[12+i] - explanations[12+i], cmap='seismic', clim=(-1, 1))\n",
    "    ax[3][i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04beab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainability import RestructuredLRP\n",
    "    \n",
    "restructured_lrp = RestructuredLRP(model, layer=20, idx=0, bottleneck=17, strategy=strategy, threshold=True)\n",
    "restructured_explanations = restructured_lrp.predict([np.expand_dims(brain, 0), \n",
    "                                                      np.expand_dims(mean_encoding, 0),\n",
    "                                                      np.expand_dims(encoding_stddev, 0)])[0]\n",
    "restructured_explanations = restructured_explanations / np.amax(np.abs(restructured_explanations))\n",
    "\n",
    "fig, ax = plt.subplots(4, 8, figsize=(15, 4))\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "    ax[0][i].imshow(brain[12+i], cmap='Greys_r')\n",
    "    ax[0][i].axis('off')\n",
    "    ax[1][i].imshow(explanations[12+i], cmap='seismic', clim=(-1, 1))\n",
    "    ax[1][i].axis('off')\n",
    "    ax[2][i].imshow(restructured_explanations[12+i], cmap='seismic', clim=(-1, 1))\n",
    "    ax[2][i].axis('off')\n",
    "    ax[3][i].imshow(restructured_explanations[12+i] - explanations[12+i], cmap='seismic', clim=(-1, 1))\n",
    "    ax[3][i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c46956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = Model(model.input, model.layers[17].output)\n",
    "\n",
    "strategy = LRPStrategy(\n",
    "    layers=[\n",
    "        {'flat': True},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1}\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 8, figsize=(15, 3))\n",
    "\n",
    "for i in range(8):\n",
    "    ax[i].imshow(brain[12+i], cmap='Greys_r')\n",
    "    ax[i].axis('off')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "for i in range(32):\n",
    "    explainer = LayerwiseRelevancePropagator(tmp, layer=17, idx=i, strategy=strategy)\n",
    "    explanations = explainer.predict(np.expand_dims(brain, 0))[0]\n",
    "\n",
    "    if np.sum(explanations) == 0:\n",
    "        continue\n",
    "    \n",
    "    explanations = explanations / np.amax(np.abs(explanations))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 8, figsize=(15, 8))\n",
    "\n",
    "    for j in range(8):\n",
    "        ax[j].imshow(explanations[12+j], cmap='seismic', clim=(-1, 1))\n",
    "        ax[j].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3176bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = encoder.predict(train_X)\n",
    "\n",
    "correlations = [[np.corrcoef(train_encodings[:,i], train_encodings[:,j])[0,1] \\\n",
    "                 for i in range(32)] for j in range(32)]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "heatmap = plt.imshow(correlations, clim=(0, 1))\n",
    "plt.colorbar(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.constraints import MinMaxNorm\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.layers import GlobalMaxPooling3D, Reshape\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "regularizer = l2(1e-3)\n",
    "depths = [32, 64, 128, 256, 256, 64]\n",
    "activation='relu'\n",
    "dropout=0.5\n",
    "\n",
    "inputs = Input((IMAGE_SIZE, IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "x = inputs\n",
    "\n",
    "for i in range(3):\n",
    "    x = Conv3D(depths[i], (3, 3, 3), padding='SAME',\n",
    "               activation=None, kernel_regularizer=regularizer,\n",
    "               bias_regularizer=regularizer)(x)\n",
    "\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation)(x)\n",
    "    x = MaxPooling3D((2, 2, 2))(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Activation(activation)(x)\n",
    "x = Reshape((-1,))(x)\n",
    "x = Dropout(dropout)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(activation)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(activation)(x)\n",
    "\n",
    "x = Dense(32, activation=None)(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dense(1, activation=None, bias_initializer=Constant([5.]), \n",
    "          bias_constraint=MinMaxNorm(min_value=5.0, max_value=5.0))(x)\n",
    "\n",
    "model = Model(inputs, x)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a2cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model.compile(loss='mse', optimizer=Adam(1e-3), metrics=['mae'])\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(\n",
    "        monitor=\"loss\",\n",
    "        factor=0.1,\n",
    "        patience=10,\n",
    "        min_lr=1e-5\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        min_delta=0,\n",
    "        patience=50,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(train_X, train_y, \n",
    "                    validation_data=(val_X, val_y), \n",
    "                    batch_size=32,\n",
    "                    epochs=500,\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "\n",
    "traces = [\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(history.history['loss'])),\n",
    "        y=history.history['loss'],\n",
    "        name='Training loss'\n",
    "    ),\n",
    "    go.Scatter(\n",
    "        x=np.arange(len(history.history['loss'])),\n",
    "        y=history.history['val_loss'],\n",
    "        name='Validation loss'\n",
    "    )\n",
    "]\n",
    "\n",
    "iplot(go.Figure(traces))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4fad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainability import LayerwiseRelevancePropagator\n",
    "\n",
    "strategy = LRPStrategy(\n",
    "    layers=[\n",
    "        {'flat': True},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'epsilon': 0.25},\n",
    "        {'epsilon': 0.25}\n",
    "    ]\n",
    ")\n",
    "\n",
    "explainer = LayerwiseRelevancePropagator(model, layer=25, idx=0, strategy=strategy)\n",
    "explanations = explainer.predict(np.expand_dims(brain, 0))[0]\n",
    "explanations = explanations / np.amax(np.abs(explanations))\n",
    "\n",
    "fig, ax = plt.subplots(8, 8, figsize=(15, 8))\n",
    "\n",
    "for i in range(0, 8, 2):\n",
    "    for j in range(8):\n",
    "        idx = ((i // 2) * 8)+ j\n",
    "        \n",
    "        ax[i][j].imshow(brain[idx], cmap='Greys_r')\n",
    "        ax[i][j].axis('off')\n",
    "        ax[i+1][j].imshow(explanations[idx], cmap='seismic', clim=(-1, 1))\n",
    "        ax[i+1][j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018d68f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = Model(model.input, model.layers[-2].output)\n",
    "\n",
    "strategy = LRPStrategy(\n",
    "    layers=[\n",
    "        {'flat': True},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'epsilon': 0.25}\n",
    "    ]\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 8, figsize=(15, 3))\n",
    "\n",
    "for i in range(8):\n",
    "    ax[i].imshow(brain[12+i], cmap='Greys_r')\n",
    "    ax[i].axis('off')\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "for i in range(32):\n",
    "    explainer = LayerwiseRelevancePropagator(tmp, layer=len(tmp.layers)-1, idx=i, strategy=strategy)\n",
    "    explanations = explainer.predict(np.expand_dims(brain, 0))[0]\n",
    "\n",
    "    if np.sum(explanations) == 0:\n",
    "        continue\n",
    "    \n",
    "    explanations = explanations / np.amax(np.abs(explanations))\n",
    "\n",
    "    fig, ax = plt.subplots(1, 8, figsize=(15, 8))\n",
    "\n",
    "    for j in range(8):\n",
    "        ax[j].imshow(explanations[12+j], cmap='seismic', clim=(-1, 1))\n",
    "        ax[j].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91792629",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(model.input, model.layers[-2].output)\n",
    "\n",
    "train_encodings = encoder.predict(train_X)\n",
    "\n",
    "correlations = [[np.corrcoef(train_encodings[:,i], train_encodings[:,j])[0,1] \\\n",
    "                 for i in range(32)] for j in range(32)]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "heatmap = plt.imshow(correlations, clim=(0, 1))\n",
    "plt.colorbar(heatmap)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99d76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = LRPStrategy(\n",
    "    layers=[\n",
    "        {'flat': True},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'alpha': 2, 'beta': 1},\n",
    "        {'epsilon': 0.25},\n",
    "        {'epsilon': 0.25}\n",
    "    ]\n",
    ")\n",
    "\n",
    "explainer = LayerwiseRelevancePropagator(model, layer=len(model.layers) - 1, idx=0, strategy=strategy)\n",
    "explanations = explainer.predict(np.expand_dims(brain, 0))[0]\n",
    "explanations = explanations / np.amax(np.abs(explanations))\n",
    "\n",
    "fig, ax = plt.subplots(8, 8, figsize=(15, 8))\n",
    "\n",
    "for i in range(0, 8, 2):\n",
    "    for j in range(8):\n",
    "        idx = ((i // 2) * 8)+ j\n",
    "        \n",
    "        ax[i][j].imshow(brain[idx], cmap='Greys_r')\n",
    "        ax[i][j].axis('off')\n",
    "        ax[i+1][j].imshow(explanations[idx], cmap='seismic', clim=(-1, 1))\n",
    "        ax[i+1][j].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1edd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainability import RestructuredLRP\n",
    "    \n",
    "restructured_lrp = RestructuredLRP(model, layer=25, idx=0, bottleneck=23, strategy=strategy)\n",
    "restructured_explanations = restructured_lrp.predict([np.expand_dims(brain, 0), \n",
    "                                                      np.expand_dims(mean_encoding, 0)])[0]\n",
    "restructured_explanations = restructured_explanations / np.amax(np.abs(restructured_explanations))\n",
    "\n",
    "fig, ax = plt.subplots(4, 8, figsize=(15, 4))\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "    ax[0][i].imshow(brain[12+i], cmap='Greys_r')\n",
    "    ax[0][i].axis('off')\n",
    "    ax[1][i].imshow(explanations[12+i], cmap='seismic', clim=(-1, 1))\n",
    "    ax[1][i].axis('off')\n",
    "    ax[2][i].imshow(restructured_explanations[12+i], cmap='seismic', clim=(-1, 1))\n",
    "    ax[2][i].axis('off')\n",
    "    ax[3][i].imshow(restructured_explanations[12+i] - explanations[12+i], cmap='seismic', clim=(-1, 1))\n",
    "    ax[3][i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bbffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(model.input, model.layers[-3].output)\n",
    "encodings = encoder.predict(test_X)\n",
    "group_idx = np.where(test_y == 5)[0]\n",
    "group_encodings = encodings[group_idx]\n",
    "mean_encoding = np.mean(group_encodings, axis=0)\n",
    "encoding_stddev = np.std(group_encodings, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f7ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainability import RestructuredLRP\n",
    "    \n",
    "restructured_lrp = RestructuredLRP(model, layer=25, idx=0, bottleneck=23, strategy=strategy, threshold=True)\n",
    "restructured_explanations = restructured_lrp.predict([np.expand_dims(brain, 0), \n",
    "                                                      np.expand_dims(mean_encoding, 0),\n",
    "                                                      np.expand_dims(encoding_stddev * 8, 0)])[0]\n",
    "restructured_explanations = restructured_explanations / np.amax(np.abs(restructured_explanations))\n",
    "\n",
    "fig, ax = plt.subplots(4, 8, figsize=(15, 4))\n",
    "\n",
    "\n",
    "for i in range(8):\n",
    "    ax[0][i].imshow(brain[12+i], cmap='Greys_r')\n",
    "    ax[0][i].axis('off')\n",
    "    ax[1][i].imshow(explanations[12+i], cmap='seismic', clim=(-1, 1))\n",
    "    ax[1][i].axis('off')\n",
    "    ax[2][i].imshow(restructured_explanations[12+i], cmap='seismic', clim=(-1, 1))\n",
    "    ax[2][i].axis('off')\n",
    "    ax[3][i].imshow(restructured_explanations[12+i] - explanations[12+i], cmap='seismic', clim=(-1, 1))\n",
    "    ax[3][i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a4681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3e02fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
